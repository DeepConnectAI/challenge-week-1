{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Video :\n",
    "\n",
    "#### Dataset Link:\n",
    "Dataset can be found at \" /data/videos/ \" in the respective challenge's repo.\n",
    "\n",
    "#### Description:\n",
    "Video series is just a sequence of images arranged in a specific order. Images of that sequence are called frames. Therefore, in video intelligence tasks, we take advantage of the temporal nature of video and semantic content in consecutive frames.\n",
    "\n",
    "#### Objective:\n",
    "How to read video data and convert it into useable format for machine learning\n",
    "\n",
    "#### Tasks:\n",
    "- Load dataset from provided link. Videos are in “.mp4” format.\n",
    "- Extract frames from video at fps=10 (opencv’s VideoCapture Class)\n",
    "- Plot 4th frame of 'VID_2.mp4' (matplotlib or Pillow library)\n",
    "- Print dimensions of any single frame of 'VID_6.mp4'\n",
    "- Print all pixel values of 10th frame of 'VID_14.mp4'\n",
    "- Perform sanity check for each video whether all frames have same dimensions or not\n",
    "\n",
    "#### Further fun (will not be evaluated):\n",
    "_Prerequisites: CNN and image processing_\n",
    "\n",
    "- We will perform video classification for fun on this sample dataset. You can download labels here: _(Link to be added soon or self-annotation for small dataset is also possible)_\n",
    "- Train image classifier on all frames extracted at fps=10 from all videos.\n",
    "- The naive approach to do video classification would be to classify each frame and save results in sequential format, and that is it !! Obviously there are much better ways of doing video classification taking advantage of the temporal nature of data.\n",
    "\n",
    "#### Helpful Links:\n",
    "- Detailed description of how to process video frames: https://www.youtube.com/watch?v=tQetgoLy70s\n",
    "- Nice tutorial on video classification: https://www.analyticsvidhya.com/blog/2018/09/deep-learning-video-classification-python/\n",
    "- Used .avi format but the idea is same: https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/\n",
    "- Line-by-Line explanation of video classification code: https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # For handling videos\n",
    "import matplotlib.pyplot as plt # For plotting images, you can use pillow library as well\n",
    "import numpy as np # For mathematical operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the video from a file\n",
    "videoFile = 'data/videos/VID_2.mp4'\n",
    "cap = cv2.VideoCapture(videoFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frame rate of video\n",
    "frameRate = cap.get(5)\n",
    "print(\"Frame rate of video:\", frameRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time length of video\n",
    "total_frames = cap.get(7)\n",
    "print(\"Total frames:\", total_frames)\n",
    "print(\"Length of video: %.2f seconds\" % (total_frames/frameRate))\n",
    "# https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frame width and height\n",
    "width  = cap.get(3)\n",
    "height = cap.get(4)\n",
    "print(\"(width, height) = \", (width,height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining desired fps\n",
    "desired_fps = 10\n",
    "frame_skipping_rate = int(np.ceil(frameRate / desired_fps))\n",
    "print(\"Frame skipping rate:\", frame_skipping_rate, \"frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store frames\n",
    "frames = []\n",
    "# Start extracting frames till we reach the end of the loop\n",
    "while(cap.isOpened()):\n",
    "    # Get the current frame number\n",
    "    frameId = cap.get(1)\n",
    "    # Reads the next incoming frame\n",
    "    ret, frame = cap.read()\n",
    "    # If we reached the end of the video, then ret returns true\n",
    "    if (ret != True):\n",
    "        break\n",
    "    \n",
    "    if (frameId % frame_skipping_rate == 0):\n",
    "        frames.append(frame)\n",
    "\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHWC\n",
    "single_video = np.array(frames)\n",
    "print(\"NHWC format:\", single_video.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotted 4th frame of 2nd video\")\n",
    "plt.imshow(single_video[3,:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions of 5th frame of 6th video\")\n",
    "single_video[4,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_video[13,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's the solution now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filenames = glob.glob('data/videos/*.mp4')\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = {}\n",
    "for file in filenames:\n",
    "    cap = cv2.VideoCapture(file)\n",
    "    frameRate = cap.get(5)\n",
    "    desired_fps = 10\n",
    "    frame_skipping_rate = int(np.ceil(frameRate / desired_fps))\n",
    "    # Store frames\n",
    "    frames = []\n",
    "    # Start extracting frames till we reach the end of the loop\n",
    "    while(cap.isOpened()):\n",
    "        # Get the current frame number\n",
    "        frameId = cap.get(1)\n",
    "        # Reads the next incoming frame\n",
    "        ret, frame = cap.read()\n",
    "        # If we reached the end of the video, then ret returns true\n",
    "        if (ret != True):\n",
    "            break\n",
    "\n",
    "        if (frameId % frame_skipping_rate == 0):\n",
    "            frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    frames = np.array(frames)\n",
    "    videos[file] = frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of videos:\", len(videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(videos[\"data/videos\\\\VID_2.mp4\"][3,:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos[\"data/videos\\\\VID_6.mp4\"][4,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos[\"data/videos\\\\VID_14.mp4\"][13,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_check = True\n",
    "dim_set = set()\n",
    "for video in videos.values():\n",
    "    dim_set.add(video[0].shape) # Get dimensions of first frame and add it in set\n",
    "if len(dim_set)>1:\n",
    "    sanity_check = False\n",
    "print(\"Sanity check:\", sanity_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
